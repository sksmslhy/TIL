{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04. 카운트 기반의 단어 표현.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMDnedcNh0vP8MQvjDr6jDx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sksmslhy/TIL/blob/master/04_%EC%B9%B4%EC%9A%B4%ED%8A%B8_%EA%B8%B0%EB%B0%98%EC%9D%98_%EB%8B%A8%EC%96%B4_%ED%91%9C%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYw4vSy-Nm_o",
        "outputId": "d2c0a375-4337-4467-96c7-8ae5675c04e9"
      },
      "source": [
        "pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDSyWpDfS6ht",
        "outputId": "3ba6df0e-4aee-4f8d-c830-1063ce8485f2"
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R9SjcAtS6xh",
        "outputId": "fdd8e04b-a33c-4fab-ded8-39a68d7aa309"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4pLq5UVNvcp"
      },
      "source": [
        "# **04. 카운트 기반의 단어 표현(Count based ward Representation)**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXmmiAmm2p93"
      },
      "source": [
        "## **1) 다양한 단어의 표현 방법**\n",
        "### **1. 단어의 표현 방법**\n",
        "* 국소 표현 (aka 이산 표현) : 해당 단어 그 자체만 보고 특정값을 맵핑해 단어 표현\n",
        "* 분산 표현 (aka 연속 표현) : 그 단어를 표현하고자 주변을 참고해 단어 표현\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160X4nBP349T"
      },
      "source": [
        "### **2. 단어 표현의 카테고리화**\n",
        "  <img src=\"https://wikidocs.net/images/page/31767/wordrepresentation.PNG\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G5AJlfv4DmP"
      },
      "source": [
        "---\n",
        "## **2) Bag of Words(BoW)**\n",
        "### **1. Bag of Words란?**\n",
        "단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법.  \n",
        "각 단어가 등장한 횟수를 수치화하는 텍스트 표현 방법이기 때문에, 주로 어떤 단어가 얼마나 등장했는지를 기준으로 문서가 어떤 성격의 문서인지를 판단하는 작업에 쓰임.\n",
        "\n",
        "- BoW를 만드는 과정  \n",
        "(1) 각 단어에 고유한 정수 인덱스를 부여  \n",
        "(2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터 생성  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tf3EIFsNii2",
        "outputId": "648581a4-77d9-4bd0-83ba-5fce702f9d81"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import re  \n",
        "okt=Okt()  \n",
        "\n",
        "token=re.sub(\"(\\.)\",\"\",\"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\")  \n",
        "# 정규 표현식을 통해 온점을 제거하는 정제 작업\n",
        "token=okt.morphs(token)  \n",
        "# OKT 형태소 분석기를 통해 토큰화 작업을 수행한 뒤에, token에 넣음\n",
        "\n",
        "word2index={}  \n",
        "bow=[]  \n",
        "for voca in token:  \n",
        "         if voca not in word2index.keys():  \n",
        "             word2index[voca]=len(word2index)  \n",
        "# token을 읽으며, word2index에 없는 (not in) 단어는 새로 추가, 이미 있는 단어는 넘어감\n",
        "             bow.insert(len(word2index)-1,1)\n",
        "# 단어의 개수는 최소 1개 이상이므로 BoW 전체에 전부 기본값 1을 넣어줍니다.\n",
        "         else:\n",
        "            index=word2index.get(voca)\n",
        "# 재등장하는 단어의 인덱스를 받아옴\n",
        "            bow[index]=bow[index]+1\n",
        "# 재등장한 단어는 해당하는 인덱스의 위치에 1을 더해줌\n",
        "print(word2index)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huHO61-HOHUP",
        "outputId": "ac44f029-e512-48f0-f160-ca3e60b65821"
      },
      "source": [
        "bow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 1, 1, 2, 1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QO3GonPQAcx"
      },
      "source": [
        "### **3. CountVectorizer 클래스로 BoW만들기**\n",
        "사이킷 런에서는 단어의 빈도를 count하여 vector로 만드는 클래스 지원.(CountVectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBJBQIZMQRXr",
        "outputId": "12c6d798-eeb2-4ff2-c52e-d710df6973e9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = ['you know I want your love. because I love you.']\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지를 보여줌"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 2 1 2 1]]\n",
            "{'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3A2ir-yU3PT"
      },
      "source": [
        "CountVectorizer는 길이가 2 이상인 문자에 대해서만 토큰으로 인식, 어절 기준으로 단어를 자른다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiabLNIqRIFc"
      },
      "source": [
        "### **4. 불용어 제거한 BoW 만들기**\n",
        "불용어 : 자연어 처리에서 큰 의미 없는 단어  \n",
        "CountVectorizer는 불용어 지정 기능 **있음**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yUly-uVResP",
        "outputId": "6eaf5294-2537-4763-808f-b91d80824b36"
      },
      "source": [
        "# 사용자가 직접 정의한 불용어 사용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=[\"the\", \"an\", \"is\", \"not\"])\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJUk9OWlRe16",
        "outputId": "4cc3cb4e-5ec5-4002-8be5-cf4d7cd5fbe8"
      },
      "source": [
        "# ContVectorizer에서 제공하는 자체 불용어 사용\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "vect = CountVectorizer(stop_words=\"english\")\n",
        "print(vect.fit_transform(text).toarray())\n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1]]\n",
            "{'family': 0, 'important': 1, 'thing': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0R-xjHSRe83",
        "outputId": "02419450-883f-40cf-88c3-056ab0f266a1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text=[\"Family is not an important thing. It's everything.\"]\n",
        "sw = stopwords.words(\"english\")\n",
        "vect = CountVectorizer(stop_words =sw)\n",
        "print(vect.fit_transform(text).toarray()) \n",
        "print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 1 1]]\n",
            "{'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvOAqVk3Q3-u"
      },
      "source": [
        "---\n",
        "## **3) 문서 단어 행렬(Document-Term Matrix, DTM)**\n",
        "서로 다른 문서들의 BoW들을 결합한 표현 방법. 행과 열을 반대로 선택하면 TDM이라고 부르기도 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WY1rfApITug6"
      },
      "source": [
        "### **1. 문서 단어 행렬의 표기법**\n",
        "DTM : 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것. 각 문서에 대한 BoW를 하나의 행렬로 만든 것으로 생각할 수 있으며 BoW 표현을 다수의 문서에 대해서 행렬로 표현하고 부르는 용어.\n",
        "\n",
        "문서 1: 먹고 싶은 사과  \n",
        "문서 2 : 먹고 싶은 바나나  \n",
        "문서 3: 길고 노란 바나나 바나나  \n",
        "문서 4 : 저는 과일이 좋아요  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LKJZqAlVp5u"
      },
      "source": [
        "|-|과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|\n",
        "|---|---|---|---|---|---|---|---|---|---|\n",
        "|문서 1|0|0|0|1|0|1|1|0|0|\n",
        "|문서 2|0|0|0|1|1|0|1|0|0|\n",
        "|문서 3|0|1|1|0|2|0|0|0|0|\n",
        "|문서 4|1|0|0|0|0|0|0|1|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3YkLO1RVnlg"
      },
      "source": [
        "### **2. 문서 단어 행렬의 한계**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcAqsWSSV25U"
      },
      "source": [
        "**1) 희소 표현 (Sparse representation**  \n",
        "one-hot-vector의 단점을 가짐. DTM에서의 각 행을 문서 벡터라고 하면, 각 문서 벡터의 차원은 전체 단어 집합의 크기를 가짐. 많은 문서 벡터가 대부분의 값이 0을 가질 수도 있음.\n",
        "\n",
        "Sparse Vector : 대부분의 값이 0인 벡터. 많은 양의 저장 공간과 계산을 위한 리소스를 필요로 함. 따라서 BoW에서 단어 집합의 크기를 줄이는 것이 중요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cD9SYg28V3Fk"
      },
      "source": [
        "**2) 단순 빈도 수 기반 접근**  \n",
        "영어에 대해 DTM을 만들었을 때 불용어인 the는 어떤 문서이든 자주 등장. 유사한 문서인지 비교하고 싶은 문서1, 문서2, 문서3에서 동일하게 the가 빈도수가 높다고 해서 이들이 유사하다고 판단? -> No!  \n",
        "\n",
        "불용어와 중요한 단어에 대해 가중치를 줄 수 있는 방법은 없을까 -> **TF-IDF**!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw3VE0U6W9Lc"
      },
      "source": [
        "---\n",
        "## **TF-IDF(Term Frequency-Inverse Document Frequency)**\n",
        "기존의 DTM을 사용하는 것보다 보다 더 많은 정보를 고려해 문서 비교 가능! (but TF-IDF가 DTM보다 항상 성능이 뛰어난 것은 아니다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ0iK8KsXZX6"
      },
      "source": [
        "### **1. TF-IDF(단어 빈도-역 문서 빈도, Term Frequency-Inverse Document Frequency)**\n",
        "단어의 빈도와 역 문서 빈도를 사용해 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법. DTM을 만든 후, TD-IDF 가중치를 부여한다.  \n",
        "TF-IDF는 주로 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 쓰일 수 있다.\n",
        "TF-IDF는 TF와 IDF를 곱한 값을 의미. 문서를 d, 단어를 t, 문서의 총 개수를 n이라고 표현할 때 TF, DF, IDF는 각각 다음과 같이 정의할 수 있다.  \n",
        "\n",
        "(1) tf(d,t) : 특정 문서 d에서의 특정 단어 t의 등장 횟수.  \n",
        "- TF는 DTM의 예제에서 각 단어들이 가진 값.\n",
        "\n",
        "(2) df(t) : 특정 단어 t가 등장한 문서의 수. 몇 번 등장했는지는 관심 X  \n",
        "\n",
        "(3) idf(d, t) : df(t)에 반비례하는 수.\n",
        "- $idf(d, t) = log(\\frac{n}{1+df(t)})$  \n",
        "\n",
        "\n",
        "TF-IDF는 모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단, 특정 문서에만 자주 등장하는 단어는 중요도가 높다고 판단. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXlYCtbkfCQT"
      },
      "source": [
        "|-|과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|\n",
        "|---|---|---|---|---|---|---|---|---|---|\n",
        "|문서 1|0|0|0|1|0|1|1|0|0|\n",
        "|문서 2|0|0|0|1|1|0|1|0|0|\n",
        "|문서 3|0|1|1|0|2|0|0|0|0|\n",
        "|문서 4|1|0|0|0|0|0|0|1|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A1rI_hIfg4N"
      },
      "source": [
        "TF == DTM, IDF를 구하자!  \n",
        "분자 : 문서의 총 수 -> 4  \n",
        "분모 : 각 단어가 등장한 문서의 수(DF)\n",
        "\n",
        "|단어|IDF(역 문서 빈도)|\n",
        "|-|-|\n",
        "|과일이|ln(4/(1+1)) = 0.693147|\n",
        "|길고|ln(4/(1+1)) = 0.693147|\n",
        "|노란|ln(4/(1+1)) = 0.693147|\n",
        "|먹고|ln(4/(2+1)) = 0.287682|\n",
        "|바나나|ln(4/(2+1)) = 0.287682|\n",
        "|사과|ln(4/(1+1)) = 0.693147|\n",
        "|싶은|ln(4/(2+1)) = 0.287682|\n",
        "|저는|ln(4/(1+1)) = 0.693147|\n",
        "|좋아요|ln(4/(1+1)) = 0.693147|\n",
        "\n",
        "TF-IDF 계산하기\n",
        "\n",
        "|-|과일이|길고|노란|먹고|바나나|사과|싶은|저는|좋아요|\n",
        "|---|---|---|---|---|---|---|---|---|---|\n",
        "|문서 1|0|0|0|0.287682|0|0.693147|0.287682|0|0|\n",
        "|문서 2|0|0|0|0.287682|0.287682|0|0.287682|0|0|\n",
        "|문서 3|0|0.693147|0.693147|0|0.575364|0|0|0|0|\n",
        "|문서 4|0.693147|0|0|0|0|0|0|0.693147|0.693147|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bxb-tjbhSLo"
      },
      "source": [
        "### **파이썬으로 TF-IDF 직접 구현하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OWCy-0OXN9y"
      },
      "source": [
        "import pandas as pd\n",
        "from math import log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p79_BieUhaSx"
      },
      "source": [
        "docs = [\n",
        "  '먹고 싶은 사과',\n",
        "  '먹고 싶은 바나나',\n",
        "  '길고 노란 바나나 바나나',\n",
        "  '저는 과일이 좋아요'\n",
        "] \n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMKH1rcmhdmJ"
      },
      "source": [
        "N = len(docs) # 총 문서의 수\n",
        "\n",
        "def tf(t, d):\n",
        "    return d.count(t)\n",
        "\n",
        "def idf(t):\n",
        "    df = 0\n",
        "    for doc in docs:\n",
        "        df += t in doc\n",
        "    return log(N/(df + 1))\n",
        "\n",
        "def tfidf(t, d):\n",
        "    return tf(t,d)* idf(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "6_fvERWWhiVd",
        "outputId": "cbc9c771-1edb-4a31-ccfa-e7eed4893d68"
      },
      "source": [
        "# TF(DTM)구하기\n",
        "result = []\n",
        "for i in range(N): # 각 문서에 대해서 아래 명령을 수행\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]        \n",
        "        result[-1].append(tf(t, d))\n",
        "\n",
        "tf_ = pd.DataFrame(result, columns = vocab)\n",
        "tf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
              "0    0   0   0   1    0   1   1   0    0\n",
              "1    0   0   0   1    1   0   1   0    0\n",
              "2    0   1   1   0    2   0   0   0    0\n",
              "3    1   0   0   0    0   0   0   1    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "tAe3exdghkS0",
        "outputId": "54a53ad6-f5ce-44d6-b9d9-041c28c33d94"
      },
      "source": [
        "result = []\n",
        "for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "    result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
        "idf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>과일이</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>길고</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>노란</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>먹고</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>바나나</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>사과</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>싶은</th>\n",
              "      <td>0.287682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>저는</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>좋아요</th>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          IDF\n",
              "과일이  0.693147\n",
              "길고   0.693147\n",
              "노란   0.693147\n",
              "먹고   0.287682\n",
              "바나나  0.287682\n",
              "사과   0.693147\n",
              "싶은   0.287682\n",
              "저는   0.693147\n",
              "좋아요  0.693147"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "zpjiIVxZhrYr",
        "outputId": "1fa98d39-52d1-453d-a299-296acc453068"
      },
      "source": [
        "# TF-IDF 행렬 출력\n",
        "result = []\n",
        "for i in range(N):\n",
        "    result.append([])\n",
        "    d = docs[i]\n",
        "    for j in range(len(vocab)):\n",
        "        t = vocab[j]\n",
        "\n",
        "        result[-1].append(tfidf(t,d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>과일이</th>\n",
              "      <th>길고</th>\n",
              "      <th>노란</th>\n",
              "      <th>먹고</th>\n",
              "      <th>바나나</th>\n",
              "      <th>사과</th>\n",
              "      <th>싶은</th>\n",
              "      <th>저는</th>\n",
              "      <th>좋아요</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.287682</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.575364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        과일이        길고        노란  ...        싶은        저는       좋아요\n",
              "0  0.000000  0.000000  0.000000  ...  0.287682  0.000000  0.000000\n",
              "1  0.000000  0.000000  0.000000  ...  0.287682  0.000000  0.000000\n",
              "2  0.000000  0.693147  0.693147  ...  0.000000  0.000000  0.000000\n",
              "3  0.693147  0.000000  0.000000  ...  0.000000  0.693147  0.693147\n",
              "\n",
              "[4 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCI46ypshxWC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY4CCD0Lh4gr"
      },
      "source": [
        "만약 전체 문서의 수 n이 4인데, $df(t)$의 값이 3인 경우? $df(t)$에 1이 더해지면서 $log$항의 분자와 분모의 값이 같아지게 됨.  \n",
        "이는 $log$의 진수값이 1이 되면서 $idf(d,t)$의 값이 0이 됨을 의미. 식으로 표현하면 $idf(d,t)=log(n/(df(t)+1))=0$. IDF의 값이 0이라면 더 이상 가중치의 역할 X. 그래서 실제 구현체는 $idf(d,t)=log(n/(df(t)+1))+1$과 같이 log항에 1을 더해줘 log항의 값이 0이 되더라도 IDF가 최소 1이상의 값을 가지도 한다.  \n",
        "사이킷런도 이 방식을 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ByOTQRLihIC"
      },
      "source": [
        "### **3. 사이킷런을 이용한 DTM과 TD-IDF 실습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu6SVWSGib9W",
        "outputId": "985e1111-4c9e-4f8e-8671-228b89f8966e"
      },
      "source": [
        "# DTM 만들기\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'you know I want your love',\n",
        "    'I like you',\n",
        "    'what should I do ',    \n",
        "]\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray()) # 코퍼스로부터 각 단어의 빈도 수를 기록\n",
        "print(vector.vocabulary_) # 각 단어의 인덱스가 어떻게 부여되었는지"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 1 0 1 0 1 1]\n",
            " [0 0 1 0 0 0 0 1 0]\n",
            " [1 0 0 0 1 0 1 0 0]]\n",
            "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE4lKEx1isLQ",
        "outputId": "b0c24dc9-8a62-4789-d0b7-a8b785453e6e"
      },
      "source": [
        "# 사이킷런은 TF-IDF를 자동 계산해주는 TfidVectorizer를 제공. \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "corpus = [\n",
        "    'you know I want your love',\n",
        "    'I like you',\n",
        "    'what should I do ',    \n",
        "]\n",
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "print(tfidfv.transform(corpus).toarray())\n",
        "print(tfidfv.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
            "  0.         0.35543247 0.46735098]\n",
            " [0.         0.         0.79596054 0.         0.         0.\n",
            "  0.         0.60534851 0.        ]\n",
            " [0.57735027 0.         0.         0.         0.57735027 0.\n",
            "  0.57735027 0.         0.        ]]\n",
            "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zssUDLPVjKUY"
      },
      "source": [
        "사이킷런의 TF-IDF는 보편적인 TF-IDF 식에서 좀 더 조정된 다른 식을 사용. 그러나 크게 다른 식은 아니며, 사이킷 런의 TF-IDF 수식을 자세히 알아보고 싶다면 [이곳](http://www.cs.pomona.edu/~dkauchak/classes/f09/cs160-f09/lectures/lecture5-tfidf.pdf) 참조."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfeUFWBWi7RN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}