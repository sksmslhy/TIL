{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_CNN_TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpFFLGxmP2we"
      },
      "source": [
        "# **CNN(Convolutional Neural Network**\r\n",
        "MNIST dataset을 CNN으로 구현해보자!  \r\n",
        "  \r\n",
        "    \r\n",
        "    \r\n",
        "\r\n",
        "## **이미지 처리에 CNN이 사용되는 이유**\r\n",
        "MLP에서의 이미지 처리 : MLP는 아래 그림과 같이 작동한다. MLP는 이미지의 shape를 2d(mztrix)에서 1d(array)로 바꾸고, 모든 노드가 fully connect되어 predction을 수행한다.  \r\n",
        "숫자 '2'를 의미하는 두 개의 다른 input이 주어졌을 때를 보자.  \r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/mlp_overview.png\" height=\"300\"></p>\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/mlp_overview2.png\" height=\"300\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkWzVqcSRY3k"
      },
      "source": [
        "target number가 같더라도('2), input array는 매우 다른 것을 볼 수 있다.  \r\n",
        "MLP는 오직 input array만 알고 있으므로, 두 개의 숫자가 같은 수라는 것을 학습하는 것은 어렵다.  \r\n",
        "이를 해결하기 위해 MLP에 노드를 추가할 수 있지만, 이것은 train 시간을 길게 하며, high computation이 필요하다.  \r\n",
        "  \r\n",
        "\r\n",
        "MLP의 issue:  \r\n",
        "1. 숫자가 다른 픽셀로 주어지면, MLP에서는 완전히 다른 input이 된다.  \r\n",
        "2. 노드가 많으면 높은 계산과 긴 train시간이 필요하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbxo1a3FS4P8"
      },
      "source": [
        "## 사물을 인식하는 방법\r\n",
        "MLP의 issue를 해결하기 위해, 실제로 우리가 숫자를 인식하는 방법을 생각해본다.  \r\n",
        "숫자 '2'를 볼 때, 우리는 그것이 2인지 어떻게 알까?  \r\n",
        "뇌는 의식적 혹은 무의식적으로 2의 머리와 꼬리, 머리와 꼬리 사이의 대각선 연결부를 다음과 같이 인식한다.\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/cnn_filter.png\" height=\"270\"></p>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGGugkjtTcay"
      },
      "source": [
        "## CNN도 사람과 같은 원리로 사물 인식을 한다!\r\n",
        "CNN은 사물의 특징(위 예제에서는 머리, 꼬리, 가운데 연결부)을 캡쳐하고 숫자를 인식하도록 훈련된다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVoQk9tQUSZe"
      },
      "source": [
        "## CNN이 특징을 구별하는 방법\r\n",
        "MLP와 대조적으로, CNN은 머리, 꼬리, 연결부와 같은 local 연결을 캡쳐하기 위해 2차원 정보를 사용한다. (2-dimension)  \r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/stride.png\" height=\"180\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5v_lz_QVQMS"
      },
      "source": [
        "CNN slide는 왼쪽 상단에서 오른쪽 하단까지 필터링 된다. sliding filter를 **Stride**라고 한다.  \r\n",
        "**Filter**는 특징을 구별하는 것이며, **Kernel**이라고도 한다.  \r\n",
        "filer가 머무르는 영역을 **Receptive Field**라고 한다. (빨간 네모)  \r\n",
        "\r\n",
        "위 사진의 필터는 대각선으로 연결된 픽셀을 식별하는 것이다.  \r\n",
        "\r\n",
        "아래 그림에서 필터는 대각선으로 연결된 픽셀을 감지한다. (숫자 2)  \r\n",
        "오른쪽 입력인 숫자 1에는 그러한 연결이 없다.\r\n",
        "\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/filter_diff.png\" height=\"140\"></p>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPbvVKqCW0w4"
      },
      "source": [
        "이미지가 gray scale이라면, 픽셀은 [0 to 255]의 숫자로 표시된다.  \r\n",
        "0은 검은색, 255는 흰색을 의미한다.\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/elem_mul.png\" height=\"420\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQQLCO_UbAvt"
      },
      "source": [
        "위의 그림에서, filter는 필터와 receptive field의 수의 요소 별 곱셈으로 특징을 파악한다.  \r\n",
        "큰 수는 특징을 가질 가능성이 많다는 것을 의미하며, 작은 수는 특징을 가질 가능성이 적다는 것을 의미한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNQFTwHKb8mz"
      },
      "source": [
        "[0 to 9]의 숫자를 탐지하려면, 직선, 수직선, 원곡선 등의 filter가 더 필요하다.  \r\n",
        "첫번째 convolution layer는 이러한 필수적인 특징을 감지하고, 그 다음 convolution layer는 이전에 탐지된 특징을 기반으로 원, 삼각형, 직사각형과 같은 더 높은 레벨의 특징을 감지할 수 있다.  \r\n",
        "모든 특징을 감지한 후, 이 특징은 MLP(Fully connected)에 입력되고 softmax를 거친 후 input을 목표 값으로 분류한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cyQD-Xni-wK"
      },
      "source": [
        "다음은 Stanford CNN 강의의 슬라이드 중 유명한 CNN Architecture다.\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/cnn_architecture.png\" height=\"320\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VNe1nbSkQ_w"
      },
      "source": [
        "CONV : convolutional layer  \r\n",
        "FC : fully connected  \r\n",
        "POOL : pooling layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pd5rUNuki1S"
      },
      "source": [
        "## Pulling layer\r\n",
        "pulling layer의 목적은 CNN 모델의 parameter와 계산을 줄이는 것이다. 따라서 overfitting을 제어한다.\r\n",
        "\r\n",
        "숫자 2의 에제에서, (stride : 1), 대각선 filter(**feature map**이라고 부른다.)의 output of stride는 다음과 같다.  \r\n",
        "FYI, Felu(feature map)은 **activation map**이라고 부른다.  \r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/stride_result.png\" height=\"500\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrtVE8GX7YdS"
      },
      "source": [
        "pooling을 적용할 때, max pooling 또는 average pooling을 사용할 수 있다.  \r\n",
        "다음은 max pooing의 예다.(2*2 filter & stride 2)\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/max_pool.png\" height=\"220\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPtFl6I07ffn"
      },
      "source": [
        "## Zero Padding\r\n",
        "zero padding은 다음과 같은 이유로 오늘날 CNN에 적용된다.\r\n",
        "1. convolutional layer에서 발생하는 정보의 손실을 줄인다.\r\n",
        "2. 입력의 경계가 어디인지 CNN이 알게 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE31ZF5b_b5N"
      },
      "source": [
        "Convolution layer에서 input dimension(5 x 5)과 output dimension(4 x 4)와 같이 작아지는 경우 정보의 손실이 생기게 된다.\r\n",
        "\r\n",
        "아래 그림에서, zero padding은 stride를 넓힐 수 있는 공간을 제공한다. filter 크기가 (3 x 3)이고 한 번에 1 pixel씩 stride 하는 경우, output dimension은 (5 x 5)로 original input과 동일하다.\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/zeropadding.png\" height=\"320\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA3njZqRBuZv"
      },
      "source": [
        "## Color 이미지에서\r\n",
        "이번 실습에서는 gray scale인 MNIST를 사용하지만 많은 이미지들은 컬러로 되어있다. 컬러 이미지는 단지 RGB가 제 겹으로 겹쳐져 있다고 생각하면 된다.\r\n",
        "\r\n",
        "\r\n",
        "28 * 28 픽셀인 10개의 gray scale 이미지가 있는 경우, 하나의 색상만 있으므로 input tensor는 (10, 28, 28, 1)이다.  \r\n",
        "28 * 28 픽셀인 10개의  RGB 이미지가 있는 경우, 3가지 색상이 있기 때문에 input tensor는 (10, 28, 28, 3)이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTHzA2IADjaz"
      },
      "source": [
        "컬러 이미지에서는 RGB 세 layer가 겹치는 것을 볼 수 있는데, 이 겹치는 layer들을 **depth**라고 한다.  \r\n",
        "아래 그림에서, 하나의 필터에 새 개의 sub 필터가 있는 것을 볼 수 있다. sub 필터는 stride를 증가시키고 각각의 stride는 feature map에 합산된다. (bias 포함)\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/rgb1.png\" height=\"320\"></p>\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/rgb2.png\" height=\"320\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf8Ges62E2E_"
      },
      "source": [
        "위 그림에서 볼 수 있듯, 각 filter의 output은 하나의 feature map이다.  \r\n",
        "따라서 첫 번째 convolution layer에 10개의 filter가 있는 경우 다음 layer의 input **depth**는 10이 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGO4OF0NFPSY"
      },
      "source": [
        "## **Train**\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/cnn_train.png\" height=\"320\"></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQEQseHeKtGH"
      },
      "source": [
        "위 그림에서 볼 수 있듯, 입력이 컬러 이미지라면 depth가 3이므로 입력에서 3개의 layer를 볼 수 있다.  \r\n",
        "첫 번째 convolution layer에는 4개의 filter가 있으므로 Conv1에 4개의 layer가 있다.  \r\n",
        "두 번째 convolution layer에는 3개의 filter가 있으므로 Conv2에 3개의 layer가 있다. pooling layer의 stride 크기가 2이므로 (2 x 2)의 feature map이 있다.  \r\n",
        "Flatten은 Fully Connected layer에 대한 입력이므로 array에 2 x 2 x 3 = 12개의 값을 가진다.  \r\n",
        "이론적으로 convolution layer는 feature를 식별한다.  \r\n",
        "Fully Connected Layer는 식별된 모든 기능을 사용하여 입력을 분류한다.  \r\n",
        "CNN은 목표 값을 알려주는 지도학습으로, back propagation(역전파)를 사용해 fully connected layer의 parameter를 최적화한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H84BT-Z3MoDX"
      },
      "source": [
        "---\r\n",
        "## **Tensorflow Implementation**\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/practice_cnn.png\" height=\"320\"></p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NRHG9DBdE1q7",
        "outputId": "ab3b20b0-e2d8-4596-8d0f-69067db814e7"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\r\n",
        "\r\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aELYve5CNuqs"
      },
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Olsg4jCXRAsc"
      },
      "source": [
        "train data는 **60000**개의 샘플이 있다.  \r\n",
        "test data는 **10000**개의 샘플이 있다.  \r\n",
        "모든 data는 **28 * 28** pixel이다.\r\n",
        "\r\n",
        "MNIST는 gray scale image이며 [0 to 255]의 값을 가진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8HXZuIgRdk2"
      },
      "source": [
        "### **data 나누기(train/validation)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObhrqDgVQ_o4"
      },
      "source": [
        "x_val = x_train[50000:60000]\r\n",
        "x_train = x_train[0:50000]\r\n",
        "y_val = y_train[50000:60000]\r\n",
        "y_train = y_train[0:50000]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWxj0CSdS3aI"
      },
      "source": [
        "### **Reshape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwNyAHKESwbN",
        "outputId": "eab80fb3-e9bd-47c8-b700-9cc3edf76616"
      },
      "source": [
        "import numpy as np\r\n",
        "x_train = np.reshape(x_train, (50000,28,28,1))\r\n",
        "x_val = np.reshape(x_val, (10000,28,28,1))\r\n",
        "x_test = np.reshape(x_test, (10000,28,28,1))\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-6d95kfXtvp"
      },
      "source": [
        "### **Normalize data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHxrWQSfTMiL"
      },
      "source": [
        "x_train = x_train.astype('float32')\r\n",
        "x_val = x_val.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "\r\n",
        "gray_scale = 255\r\n",
        "x_train /= gray_scale\r\n",
        "x_val /= gray_scale\r\n",
        "x_test /= gray_scale"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQvK_BjdYk1u"
      },
      "source": [
        "### **label to one hot encoding value**\r\n",
        "숫자 분류 할 것이므로 class는 10개"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcheZzfBYYEe"
      },
      "source": [
        "num_classes = 10\r\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\r\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rTZzSTgaBmm"
      },
      "source": [
        "### **Implement CNN tensorflow graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb26ATITY16m"
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()\r\n",
        "\r\n",
        "x = tf.compat.v1.placeholder(tf.float32, shape=[None, 28, 28, 1])\r\n",
        "y_ = tf.compat.v1.placeholder(tf.float32, shape=[None, 10])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnr4YElEYdI"
      },
      "source": [
        "parameter를 0에 가깝게 초기화.  \r\n",
        "truncated normal을 사용하는 포인트는 softmax에서 sigmoid 포화도를 극복하는 것이다.(값이 너무 크거나 작으면 neuron이 학습을 중단하므로, 학습을 효율적으로 하기 위해.)  \r\n",
        "tf.truncated_normal() 평균이 0에 가깝고 값이 0([-0.1 to 0.1])에 가까운 정규 분포에서 random num을 선택.  \r\n",
        "정규 분포에서 tail을 잘라내기 때문에 truncated라고 부른다.  \r\n",
        "tf.random_normal은 평균이 0에 가까운 정규 분포에서 random num을 선택하지만 값은 조금 더 떨어져 있을 수 있다. [-2 to 2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCUle-6gZOl9"
      },
      "source": [
        "def weight_variable(shape):\r\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\r\n",
        "  return tf.Variable(initial)\r\n",
        "\r\n",
        "def bias_variable(shape):\r\n",
        "  initial = tf.constant(0.1, shape=shape)\r\n",
        "  return tf.Variable(initial)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLjIhqd2FGv8"
      },
      "source": [
        "**padding이 SAME**이라는 것은 output feature map의 크기가 input feature map과 같다는 것을 의미한다.  \r\n",
        "ex) MNIST의 모양은 (28 x 28)이므로 출력도 (28, 28)의 shape이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwHd_K-BZ-hW"
      },
      "source": [
        "# convolution layer\r\n",
        "def conv2d(x, W):\r\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') \r\n",
        "\r\n",
        "def max_pool_2x2(x):\r\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\r\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApqMBncVGP3A"
      },
      "source": [
        "첫번째 convolution layer는 16개의 filter를 가지며 각각의 사이즈는 5 x 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvXIA7pjGPad"
      },
      "source": [
        "W_conv1 = weight_variable([5, 5, 1, 16]) # 5x5사이즈, 총 1개의 gray scale, 16개의 filter\r\n",
        "b_conv1 = bias_variable([16]) # 16개의 filter가 있으니까 bias도 16개 필요"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zskGZyq0Hint"
      },
      "source": [
        "feature map 만든 후, activation func로 ReLU 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgTX1vZkHaDJ"
      },
      "source": [
        "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-4M3-mJICjZ"
      },
      "source": [
        "convolution layer만든 후, activation map 크기를 줄이기 위해 Pooling layer를 적용한다.  \r\n",
        "Pooling layer는 parameter를 줄이고 overfitting을 제어한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOCg9v1uIAPi"
      },
      "source": [
        "h_pool1 = max_pool_2x2(h_conv1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BojKiTNnITu8"
      },
      "source": [
        "max pooling 후, input shape는 (14, 14)이다.  \r\n",
        "두 번째 convolution layer를 만든다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UYtMLy1IRW1"
      },
      "source": [
        "W_conv2 = weight_variable([5, 5, 16, 32])\r\n",
        "b_conv2 = bias_variable([32])\r\n",
        "\r\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\r\n",
        "h_pool2 = max_pool_2x2(h_conv2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHLW-MjiIf4b"
      },
      "source": [
        "max pooling 후, input shape은 (7, 7)이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_9m4MfVIl-l"
      },
      "source": [
        "## **FC (Fully Connected Layer)**\r\n",
        " CONV의 activation map을 숫자 분류의 기능으로 사용하는 FC다.  \r\n",
        " FC에 input으로 넣기 위해 activation map pixel을 하나의 array로 flatten한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX7pmqJ7IeDy"
      },
      "source": [
        "W_fc1 = weight_variable([7 * 7 * 32, 128]) \r\n",
        "b_fc1 = bias_variable([128])\r\n",
        "\r\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32]) # 7*7의 이미지와 32개의 filter로 구성되어 있었는데 이것을 하나의 array로 담는 과정\r\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1) # activate func : relu"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mkli3t_Jqg-"
      },
      "source": [
        "FC에는 hidden layer가 두 개 있다. 첫 번째 hidden layer는 128개의 node를 가지며, 두 번째 hidden layer는 목표 범위 [0 to 9]와 일치하기 위해 10개의 node를 가지고 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmkoTJS4JoAh"
      },
      "source": [
        "W_fc2 = weight_variable([128, 10])\r\n",
        "b_fc2 = bias_variable([10])\r\n",
        "\r\n",
        "y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2 # W*X+b의 형태"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea0-NNvgKZYs"
      },
      "source": [
        "loss func로 cross entopy 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxyJtyK1Kbqy"
      },
      "source": [
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfV7eOFiKseF"
      },
      "source": [
        "Adam optimizer로 parameter를 최적화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_UkCuYcKqeb"
      },
      "source": [
        "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2A8xBFjKzI1"
      },
      "source": [
        "accuracy code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BaPj5blKw9t"
      },
      "source": [
        "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\r\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xapgIjSK8uN"
      },
      "source": [
        "## **Train & Test**\r\n",
        "epoches : 5, Mini Batch 사용하고, 500개의 train data를 model에 전달할 때마다 parameter를 최적화한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUoBFDVzK7xv",
        "outputId": "350f7d67-863c-4a99-d4be-3ae84b384923"
      },
      "source": [
        "# initialize\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "\r\n",
        "# train hyperparameters\r\n",
        "epoch_cnt = 5\r\n",
        "batch_size = 500\r\n",
        "iteration = len(x_train) // batch_size\r\n",
        "\r\n",
        "# Start training\r\n",
        "with tf.Session() as sess:\r\n",
        "    tf.set_random_seed(777)\r\n",
        "    # Run the initializer\r\n",
        "    sess.run(init)\r\n",
        "    for epoch in range(epoch_cnt):\r\n",
        "        avg_loss = 0.\r\n",
        "        start = 0; end = batch_size\r\n",
        "        \r\n",
        "        for i in range(iteration):\r\n",
        "            if i%10 == 0:\r\n",
        "                train_accuracy = accuracy.eval(feed_dict={x:x_train[start: end], y_: y_train[start: end]})\r\n",
        "                print(\"step \"+ str(i) + \": training accuracy: \"+str(train_accuracy))\r\n",
        "            train_step.run(feed_dict={x:x_train[start: end], y_: y_train[start: end]})\r\n",
        "            start += batch_size; end += batch_size    \r\n",
        "        \r\n",
        "        # Validate model\r\n",
        "        val_accuracy = accuracy.eval(feed_dict={x:x_val, y_: y_val})\r\n",
        "        print(\"validation accuracy: \"+str(val_accuracy))\r\n",
        "        \r\n",
        "    test_accuracy = accuracy.eval(feed_dict={x:x_test, y_: y_test}) \r\n",
        "    print(\"test accuracy: \"+str(test_accuracy))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step 0: training accuracy: 0.108\n",
            "step 10: training accuracy: 0.698\n",
            "step 20: training accuracy: 0.834\n",
            "step 30: training accuracy: 0.876\n",
            "step 40: training accuracy: 0.886\n",
            "step 50: training accuracy: 0.904\n",
            "step 60: training accuracy: 0.926\n",
            "step 70: training accuracy: 0.942\n",
            "step 80: training accuracy: 0.94\n",
            "step 90: training accuracy: 0.928\n",
            "validation accuracy: 0.9466\n",
            "step 0: training accuracy: 0.936\n",
            "step 10: training accuracy: 0.944\n",
            "step 20: training accuracy: 0.932\n",
            "step 30: training accuracy: 0.946\n",
            "step 40: training accuracy: 0.964\n",
            "step 50: training accuracy: 0.958\n",
            "step 60: training accuracy: 0.974\n",
            "step 70: training accuracy: 0.966\n",
            "step 80: training accuracy: 0.974\n",
            "step 90: training accuracy: 0.958\n",
            "validation accuracy: 0.9716\n",
            "step 0: training accuracy: 0.966\n",
            "step 10: training accuracy: 0.982\n",
            "step 20: training accuracy: 0.956\n",
            "step 30: training accuracy: 0.968\n",
            "step 40: training accuracy: 0.978\n",
            "step 50: training accuracy: 0.976\n",
            "step 60: training accuracy: 0.974\n",
            "step 70: training accuracy: 0.97\n",
            "step 80: training accuracy: 0.984\n",
            "step 90: training accuracy: 0.978\n",
            "validation accuracy: 0.9793\n",
            "step 0: training accuracy: 0.98\n",
            "step 10: training accuracy: 0.984\n",
            "step 20: training accuracy: 0.97\n",
            "step 30: training accuracy: 0.978\n",
            "step 40: training accuracy: 0.984\n",
            "step 50: training accuracy: 0.984\n",
            "step 60: training accuracy: 0.982\n",
            "step 70: training accuracy: 0.978\n",
            "step 80: training accuracy: 0.986\n",
            "step 90: training accuracy: 0.988\n",
            "validation accuracy: 0.9809\n",
            "step 0: training accuracy: 0.982\n",
            "step 10: training accuracy: 0.982\n",
            "step 20: training accuracy: 0.974\n",
            "step 30: training accuracy: 0.982\n",
            "step 40: training accuracy: 0.986\n",
            "step 50: training accuracy: 0.986\n",
            "step 60: training accuracy: 0.982\n",
            "step 70: training accuracy: 0.98\n",
            "step 80: training accuracy: 0.984\n",
            "step 90: training accuracy: 0.99\n",
            "validation accuracy: 0.9827\n",
            "test accuracy: 0.9847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWGvAe5eK8Pb"
      },
      "source": [
        "5번의 epoches만에 **98.5**%의 test accuracy를 얻어냄."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3qMcBZEL3Sy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}