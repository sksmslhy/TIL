{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_XOR_Sol_Tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUxBX4AGUQex"
      },
      "source": [
        "# **Solving XOR with MLP**\r\n",
        "\r\n",
        "Single Perceptron only works on Linearly Separable Classification.\r\n",
        "\r\n",
        "One perceptron is one decision boundary, so it only solve linearly separable problem.\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://sungjk.github.io/images/2017/04/11/inseparable.GIF\" height=\"200\"></p>\r\n",
        "\r\n",
        "MLP with two neurons in hidden layer can solve XOR. Two neurons in hidden layer will draw two boundary lines.\r\n",
        "<p align=\"center\"><img src=\"http://cps0715.weebly.com/uploads/7/4/0/3/74035485/9513551_orig.png\" height=\"400\"></p>\r\n",
        "\r\n",
        "Because step function is hard to optimize using back propagation due to Non-differentiable, We will use sigmoid as its activation instead of step function.\r\n",
        "\r\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/minsuk-heo/deeplearning/master/img/MLP_XOR.png\" height=\"350\"></p>\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "# **Implementation with Tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "Yvp6Bal_WvTl",
        "outputId": "9f367fa0-a402-4d2e-c671-e93af09e9452"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_v2_behavior()\r\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pshgaBUkXgOT"
      },
      "source": [
        "Tensorflow는 그래프를 만들고 그래프를 training하며 최적의 변수를 만든다.\r\n",
        "\r\n",
        "Train data shape 정의\r\n",
        "XOR train data 는 input X와 output Y를 가진다.\r\n",
        "\r\n",
        "X는 다음과 같은 [4,2] shape\r\n",
        "[0, 0], [0, 1], [1, 0], [1, 1]\r\n",
        "\r\n",
        "Y는 다음과 같은 [4,1] shape\r\n",
        "[[0], [1], [1], [0]]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ddt72GWzaq"
      },
      "source": [
        "X = tf.placeholder(tf.float32, shape=[4,2])\r\n",
        "Y = tf.placeholder(tf.float32, shape=[4,1])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IywfvCGYvC8"
      },
      "source": [
        "## **First Layer** (hidden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h218abUQYIyH"
      },
      "source": [
        "# 위 그림의 구조에서, first layer는 두개의 neurons을 가지며, 두 개의 input value를 받는다\r\n",
        "W1 = tf.Variable(tf.random_uniform([2,2]))\r\n",
        "# 각각의 neuron은 bias를 가진다. bias는 노드의 개수만큼 필요해서 2.\r\n",
        "B1 = tf.Variable(tf.zeros([2]))\r\n",
        "# First layer의 output은 Z이며, sigmoid함수에 W1*X+B1의 값을 넣은 결과이다.\r\n",
        "Z = tf.sigmoid(tf.matmul(X, W1)+B1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HqVNsc5ZrSO"
      },
      "source": [
        "## **Second Layer** (hidden)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Z7AU9QZeqA"
      },
      "source": [
        "# second layer는 두 개의 output을 받아서 하나의 output을 낸다.\r\n",
        "W2 = tf.Variable(tf.random_uniform([2,1]))\r\n",
        "# 하나의 neuron은 하나의 bias를 가진다. 그래서 1.\r\n",
        "B2 = tf.Variable(tf.zeros([1]))\r\n",
        "# Second layer의 output은 Y_hat이며, sigmoid함수에 W2*Z+B2의 값을 넣은 결과이다. 이것이 prediction 값\r\n",
        "Y_hat = tf.sigmoid(tf.matmul(Z, W2) + B2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sShmJgBeauXT"
      },
      "source": [
        "## **Loss Fuction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jyKqBh-agjp"
      },
      "source": [
        "# cross entropy 사용. (classification에 주로 사용) 0 또는 1을 출력해야 하니까. (선형회귀는 MSE)\r\n",
        "loss = tf.reduce_mean(-1*((Y*tf.log(Y_hat))+((1-Y)*tf.log(1.0-Y_hat))))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGyQHsTTbPiR"
      },
      "source": [
        "## **Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcJFcgUBbOZ4"
      },
      "source": [
        "# Gradient Descent. (시그모이드는 기울기 있어서 사용 가능) learning rate = 0.05\r\n",
        "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3ERvxhJbi1G"
      },
      "source": [
        "## **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2D8g8oybdaU"
      },
      "source": [
        "# train data (XOR Operation)\r\n",
        "train_X = [[0,0],[0,1],[1,0],[1,1]]\r\n",
        "train_Y = [[0],[1],[1],[0]]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItVH49o_bsHR",
        "outputId": "fb1a069a-0628-4dc1-e7c2-7bc4c057219b"
      },
      "source": [
        "# initialize\r\n",
        "init = tf.global_variables_initializer()\r\n",
        "# Start training\r\n",
        "with tf.Session() as sess:\r\n",
        "    # Run the initializer\r\n",
        "    sess.run(init)\r\n",
        "    print(\"train data: \"+str(train_X))\r\n",
        "    for i in range(20000):\r\n",
        "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\r\n",
        "        if i % 5000 == 0:\r\n",
        "            print(\"\\nEpoch : \", i)\r\n",
        "            print('Output : \\n', sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))\r\n",
        "    \r\n",
        "    print(\"\\nFinal Output : \\n\", sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data: [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
            "\n",
            "Epoch :  0\n",
            "Output : \n",
            " [[0.5740913 ]\n",
            " [0.5955741 ]\n",
            " [0.58802474]\n",
            " [0.60746115]]\n",
            "\n",
            "Epoch :  5000\n",
            "Output : \n",
            " [[0.4134797 ]\n",
            " [0.5295733 ]\n",
            " [0.53178734]\n",
            " [0.55693287]]\n",
            "\n",
            "Epoch :  10000\n",
            "Output : \n",
            " [[0.11033994]\n",
            " [0.8586353 ]\n",
            " [0.8585152 ]\n",
            " [0.19625548]]\n",
            "\n",
            "Epoch :  15000\n",
            "Output : \n",
            " [[0.03807291]\n",
            " [0.96723753]\n",
            " [0.9672046 ]\n",
            " [0.0381839 ]]\n",
            "\n",
            "Final Output : \n",
            " [[0.02194998]\n",
            " [0.98261505]\n",
            " [0.98260194]\n",
            " [0.01933551]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0_QwzXcb9xY"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}