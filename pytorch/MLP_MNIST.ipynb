{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Practice\n",
    "\n",
    "\n",
    "> ### Multi Layer Perceptron using Pytorch on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. MLP 모델의 설계 순서\n",
    "1. module import\n",
    "2. 모델 설계 시 활용하는 장비 확인\n",
    "3. data set download (split tran/test set)\n",
    "4. data 확인\n",
    "5. MLP 모델 설계\n",
    "6. Optimizer, Objective Func 설정\n",
    "7. train data에 대한 모델 성능 확인하는 함수 정의 (ex. accuracy, loss)\n",
    "8. test data에 대한 모델의 성능 확인하는 함수 정의 (ex. accuracy, loss)\n",
    "9. MLP 학습 실행하며 tran, test set의 loss와 test set accuracy 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 설계 시 활용하는 장비 확인 (GPU?CPU?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.8.1  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 # 한 번 학습할 때 32개의 데이터를 학습한다.\n",
    "EPOCHS = 10 # 존재하고 있는 미니배치를 전부 이용하는 횟수. 즉, 학습을 몇 번 반복할 것인지."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MNIST Dataset Download\n",
    "MNIST는 사람이 손으로 쓴 숫자로 이루어지는 대형 데이터베이스다.  \n",
    "각 이미지는 28*28 pexels로 구성되며 흰색과 검정색으로 이루어진 gray scale image [0 to 255]다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
    "                               train = True,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
    "                              train = False,\n",
    "                              transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mnist 데이터는 이미지 데이터이다. 데이터를 다운로드할 때 transform을 사용해 기본적인 전처리를 진행한다. ToTensor()는 데이터를 tensor형태로 변경시킨다. 또한 각각의 픽셀은  [0 to 255] 사이의 스칼라 값으로 구성되어 있는데 이를 [0 to 1] 사이의 값으로 정규화 한다.  \n",
    "- shuffle은 데이터의 순서를 섞고자 할 때 사용한다. 모델이 학습을 진행할 때 label 정보의 순서를 암기해 학습을 진행할 우려가 있으므로 데이터 순서를 섞어 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 데이터 확인하기\n",
    "미니배치 단위로 할당한 데이터의 개수와 형태를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap = \"gray_r\")\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MLP 모델 설계\n",
    "28 * 28 픽셀의 이미지 데이터가 Flatten되어 모델의 input으로 들어간다.\n",
    "* 첫 번째 레이어는 mnist 이미지 한 장을 입력으로 받고 512개의 node를 만든다.\n",
    "* 두 번째 레이어는 512개의 input을 받고 256개의 node를 만든다.\n",
    "* 세 번째 레이어는 256개의 input을 받고 10개의 node를 만든다. (최종적으로 분류해야 할 output의 개수가 0~9까지 총 10개이므로 최종 output node 수는 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MLP, self).__init__() \n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        \n",
    "    # 설계한 모델의 forward propagation. 모델에 데이터를 입력했을 때 output을 계산하기까지의 과정\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view 메서드는 input tensor와 데이터는 같지만 shape가 다른 tensor를 반환한다. 이 메서드를 통해 flatten된 데이터는 첫 번째 레이어에 input으로 들어간다. 그 후 반환된 값은 sigmoid 함수를 통과해 두 번째 레이어의 input이 된다. 마찬가지로 그 후 반환된 값은 다시 sigmoid 함수를 통과해 세 번째 레이어의 input이 되고, 세 번째 레이어에서 반환된 값(prediction)은 log_softmax 함수를 통과해 최종 output을 계산하게 된다.(log_softmax를 사용하는 이유는 softmax보다 loss값에 대한 gradient 값을 더 원활하게 계산하기 때문.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optimizer, Objective Function 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIP\n",
    "\n",
    "torchsummary 패키지를 이용하면 pytorch에서도 keras처럼 모델을 깔끔하게 출력해볼 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]         401,920\n",
      "            Linear-2                  [-1, 256]         131,328\n",
      "            Linear-3                   [-1, 10]           2,570\n",
      "================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 2.04\n",
      "Estimated Total Size (MB): 2.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = MLP().to(DEVICE)\n",
    "summary(model, input_size=(1,28,28)) # input_size = (channels, H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train data에 대한 모델 성능 확인하는 함수 정의\n",
    "기존에 정의한 이미지 데이터와 레이블 데이터를 이용해 MLP 모델을 학습하는 함수를 정의한다.\n",
    "\n",
    "- train_loader에는 학습에 이용되는 이미지 데이터와 레이블 데이터가 mini-batch 단위로 묶여 저장되어 있다. 해당 train_loader 내의 미니배치 단위로 저장된 데이터를 순서대로 MLP 모델을 학습시킨다.  \n",
    "- 미니배치 내에 있는 데이터를 이용해 모델을 학습시키기 위해서는 모든 데이터를 DEVICE에 할당해야 한다.  \n",
    "- DEVICE에 데이터를 할당할 경우, 과거에 이용한 미니 배치 내에 있는 데이터를 바탕으로 계산된 loss의 gradient 값이 optimizer에 할당되어 있으므로 optimizer의 gradient를 초기화한다.  \n",
    "- DEVICE에 할당한 이미지를 모델의 input으로, output을 계산한다. 계산된 output과 DEVICE의 레이블 데이터를 CrossEntropy를 이용해 loss를 계산한다.  \n",
    "- loss 값을 계산한 결과를 바탕으로 backpropagation을 통해 계산된 gradient 값을 각 파라미터에 할당하고, 할당된 gradient 값을 이용해 파라미터 값을 업데이트 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(\"============================ Train ===========================\")\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Training Epoch: {}  iteration : {:5d}  Train Loss: {:.6f}\".format(epoch, batch_idx * len(image), loss.item()))\n",
    "        #if batch_idx % log_interval == 0:\n",
    "        #    print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "        #        epoch, batch_idx * len(image), \n",
    "        #        len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "        #        loss.item()))\n",
    "    print(\"==============================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test data에 대한 모델의 성능 확인하는 함수 정의\n",
    "학습의 진행 과정을 모니터링하기 위한 함수이다.\n",
    "\n",
    "- test data를 통해 모델을 평가할 때는 gradient를 통해 파라미터 값이 업데이트 되면 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. MLP 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ Train ===========================\n",
      "Training Epoch: 1  iteration :     0  Train Loss: 2.329282\n",
      "Training Epoch: 1  iteration :  6400  Train Loss: 2.310580\n",
      "Training Epoch: 1  iteration : 12800  Train Loss: 2.351052\n",
      "Training Epoch: 1  iteration : 19200  Train Loss: 2.299035\n",
      "Training Epoch: 1  iteration : 25600  Train Loss: 2.273660\n",
      "Training Epoch: 1  iteration : 32000  Train Loss: 2.318981\n",
      "Training Epoch: 1  iteration : 38400  Train Loss: 2.242330\n",
      "Training Epoch: 1  iteration : 44800  Train Loss: 2.256781\n",
      "Training Epoch: 1  iteration : 51200  Train Loss: 2.236683\n",
      "Training Epoch: 1  iteration : 57600  Train Loss: 2.270930\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 1 Test Loss: 2.2304  Test Accuracy: 0.1277\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 2  iteration :     0  Train Loss: 2.283923\n",
      "Training Epoch: 2  iteration :  6400  Train Loss: 2.219948\n",
      "Training Epoch: 2  iteration : 12800  Train Loss: 2.124277\n",
      "Training Epoch: 2  iteration : 19200  Train Loss: 2.088445\n",
      "Training Epoch: 2  iteration : 25600  Train Loss: 1.813871\n",
      "Training Epoch: 2  iteration : 32000  Train Loss: 1.891865\n",
      "Training Epoch: 2  iteration : 38400  Train Loss: 1.655784\n",
      "Training Epoch: 2  iteration : 44800  Train Loss: 1.520083\n",
      "Training Epoch: 2  iteration : 51200  Train Loss: 1.474256\n",
      "Training Epoch: 2  iteration : 57600  Train Loss: 1.086236\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 2 Test Loss: 1.2375  Test Accuracy: 0.6065\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 3  iteration :     0  Train Loss: 1.310609\n",
      "Training Epoch: 3  iteration :  6400  Train Loss: 1.110279\n",
      "Training Epoch: 3  iteration : 12800  Train Loss: 1.011217\n",
      "Training Epoch: 3  iteration : 19200  Train Loss: 0.999434\n",
      "Training Epoch: 3  iteration : 25600  Train Loss: 1.013226\n",
      "Training Epoch: 3  iteration : 32000  Train Loss: 0.708098\n",
      "Training Epoch: 3  iteration : 38400  Train Loss: 0.817066\n",
      "Training Epoch: 3  iteration : 44800  Train Loss: 0.911781\n",
      "Training Epoch: 3  iteration : 51200  Train Loss: 0.914862\n",
      "Training Epoch: 3  iteration : 57600  Train Loss: 0.754450\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 3 Test Loss: 0.7496  Test Accuracy: 0.7726\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 4  iteration :     0  Train Loss: 0.633241\n",
      "Training Epoch: 4  iteration :  6400  Train Loss: 0.652282\n",
      "Training Epoch: 4  iteration : 12800  Train Loss: 0.652666\n",
      "Training Epoch: 4  iteration : 19200  Train Loss: 1.045652\n",
      "Training Epoch: 4  iteration : 25600  Train Loss: 0.934755\n",
      "Training Epoch: 4  iteration : 32000  Train Loss: 0.450263\n",
      "Training Epoch: 4  iteration : 38400  Train Loss: 0.535218\n",
      "Training Epoch: 4  iteration : 44800  Train Loss: 0.580409\n",
      "Training Epoch: 4  iteration : 51200  Train Loss: 0.651624\n",
      "Training Epoch: 4  iteration : 57600  Train Loss: 0.500668\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 4 Test Loss: 0.5608  Test Accuracy: 0.8335\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 5  iteration :     0  Train Loss: 0.709833\n",
      "Training Epoch: 5  iteration :  6400  Train Loss: 0.485248\n",
      "Training Epoch: 5  iteration : 12800  Train Loss: 0.601257\n",
      "Training Epoch: 5  iteration : 19200  Train Loss: 0.543999\n",
      "Training Epoch: 5  iteration : 25600  Train Loss: 0.627099\n",
      "Training Epoch: 5  iteration : 32000  Train Loss: 0.494910\n",
      "Training Epoch: 5  iteration : 38400  Train Loss: 0.314658\n",
      "Training Epoch: 5  iteration : 44800  Train Loss: 0.372785\n",
      "Training Epoch: 5  iteration : 51200  Train Loss: 0.511444\n",
      "Training Epoch: 5  iteration : 57600  Train Loss: 0.605129\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 5 Test Loss: 0.4656  Test Accuracy: 0.8680\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 6  iteration :     0  Train Loss: 0.567959\n",
      "Training Epoch: 6  iteration :  6400  Train Loss: 0.477551\n",
      "Training Epoch: 6  iteration : 12800  Train Loss: 0.830728\n",
      "Training Epoch: 6  iteration : 19200  Train Loss: 0.654530\n",
      "Training Epoch: 6  iteration : 25600  Train Loss: 0.577108\n",
      "Training Epoch: 6  iteration : 32000  Train Loss: 0.567123\n",
      "Training Epoch: 6  iteration : 38400  Train Loss: 0.535277\n",
      "Training Epoch: 6  iteration : 44800  Train Loss: 0.445225\n",
      "Training Epoch: 6  iteration : 51200  Train Loss: 0.200143\n",
      "Training Epoch: 6  iteration : 57600  Train Loss: 0.828062\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 6 Test Loss: 0.4145  Test Accuracy: 0.8793\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 7  iteration :     0  Train Loss: 0.565022\n",
      "Training Epoch: 7  iteration :  6400  Train Loss: 0.259759\n",
      "Training Epoch: 7  iteration : 12800  Train Loss: 0.732533\n",
      "Training Epoch: 7  iteration : 19200  Train Loss: 0.372736\n",
      "Training Epoch: 7  iteration : 25600  Train Loss: 0.462169\n",
      "Training Epoch: 7  iteration : 32000  Train Loss: 0.596358\n",
      "Training Epoch: 7  iteration : 38400  Train Loss: 0.567300\n",
      "Training Epoch: 7  iteration : 44800  Train Loss: 0.422562\n",
      "Training Epoch: 7  iteration : 51200  Train Loss: 0.257183\n",
      "Training Epoch: 7  iteration : 57600  Train Loss: 0.208244\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 7 Test Loss: 0.3831  Test Accuracy: 0.8886\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 8  iteration :     0  Train Loss: 0.751156\n",
      "Training Epoch: 8  iteration :  6400  Train Loss: 0.308778\n",
      "Training Epoch: 8  iteration : 12800  Train Loss: 0.564286\n",
      "Training Epoch: 8  iteration : 19200  Train Loss: 0.325378\n",
      "Training Epoch: 8  iteration : 25600  Train Loss: 0.459834\n",
      "Training Epoch: 8  iteration : 32000  Train Loss: 0.122892\n",
      "Training Epoch: 8  iteration : 38400  Train Loss: 0.362788\n",
      "Training Epoch: 8  iteration : 44800  Train Loss: 0.785192\n",
      "Training Epoch: 8  iteration : 51200  Train Loss: 0.345773\n",
      "Training Epoch: 8  iteration : 57600  Train Loss: 0.199921\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 8 Test Loss: 0.3646  Test Accuracy: 0.8931\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 9  iteration :     0  Train Loss: 0.213547\n",
      "Training Epoch: 9  iteration :  6400  Train Loss: 0.120165\n",
      "Training Epoch: 9  iteration : 12800  Train Loss: 0.252859\n",
      "Training Epoch: 9  iteration : 19200  Train Loss: 0.303040\n",
      "Training Epoch: 9  iteration : 25600  Train Loss: 0.320157\n",
      "Training Epoch: 9  iteration : 32000  Train Loss: 0.302889\n",
      "Training Epoch: 9  iteration : 38400  Train Loss: 0.515862\n",
      "Training Epoch: 9  iteration : 44800  Train Loss: 0.457773\n",
      "Training Epoch: 9  iteration : 51200  Train Loss: 0.217901\n",
      "Training Epoch: 9  iteration : 57600  Train Loss: 0.226754\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 9 Test Loss: 0.3502  Test Accuracy: 0.8989\n",
      "--------------------------------------------------------------\n",
      "============================ Train ===========================\n",
      "Training Epoch: 10  iteration :     0  Train Loss: 0.498767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 10  iteration :  6400  Train Loss: 0.543210\n",
      "Training Epoch: 10  iteration : 12800  Train Loss: 0.561122\n",
      "Training Epoch: 10  iteration : 19200  Train Loss: 0.353615\n",
      "Training Epoch: 10  iteration : 25600  Train Loss: 0.081553\n",
      "Training Epoch: 10  iteration : 32000  Train Loss: 0.309431\n",
      "Training Epoch: 10  iteration : 38400  Train Loss: 0.313476\n",
      "Training Epoch: 10  iteration : 44800  Train Loss: 0.674694\n",
      "Training Epoch: 10  iteration : 51200  Train Loss: 0.137903\n",
      "Training Epoch: 10  iteration : 57600  Train Loss: 0.241868\n",
      "==============================================================\n",
      "---------------------------- Test ----------------------------\n",
      "Test Epoch: 10 Test Loss: 0.3350  Test Accuracy: 0.9020\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"---------------------------- Test ----------------------------\")\n",
    "    print(\"Test Epoch: {} Test Loss: {:.4f}  Test Accuracy: {:.4f}\".format(epoch, test_loss, test_accuracy))\n",
    "    print(\"--------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
